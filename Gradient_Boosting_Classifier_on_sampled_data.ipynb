{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradient Boosting Classifier on sampled data.ipynb",
      "provenance": [],
      "mount_file_id": "14UGW8HzpQaVx_aHdLy362N8i-hhGN7px",
      "authorship_tag": "ABX9TyPoO+r4ywugeieONi6W5Ysp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aanisha/ACL_Abusive_Tamil_Comment_Classification/blob/main/Gradient_Boosting_Classifier_on_sampled_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Boosting Classifier on the dataset\n",
        "\n",
        "The experiment here uses the data after the oversampling and under-sampling of the data."
      ],
      "metadata": {
        "id": "w946rFQWXhNe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zUtblVESanq",
        "outputId": "3aa8ee08-d935-4e09-b6c2-5b481322adc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: indic-nlp-library in /usr/local/lib/python3.7/dist-packages (0.81)\n",
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.7/dist-packages (from indic-nlp-library) (2.0.6)\n",
            "Requirement already satisfied: sphinx-argparse in /usr/local/lib/python3.7/dist-packages (from indic-nlp-library) (0.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from indic-nlp-library) (1.21.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from indic-nlp-library) (1.3.5)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.7/dist-packages (from indic-nlp-library) (1.0.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->indic-nlp-library) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->indic-nlp-library) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->indic-nlp-library) (1.15.0)\n",
            "Requirement already satisfied: sphinx>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx-argparse->indic-nlp-library) (1.8.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (21.3)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.6.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.7.12)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.3.0)\n",
            "Requirement already satisfied: docutils<0.18,>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.17.1)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.9.1)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.23.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.11.3)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (57.4.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.10)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.0.7)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.1.5)\n"
          ]
        }
      ],
      "source": [
        "# Downloading library\n",
        "\n",
        "!pip install indic-nlp-library"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "CoyLxBvjTCli"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocessing the data"
      ],
      "metadata": {
        "id": "VVkflqT8bRdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/Tamil_train_data.csv')\n",
        "test = pd.read_csv('/content/Tamil_test_data.csv')\n",
        "valid = pd.read_csv('/content/Tamil_valid_data.csv')"
      ],
      "metadata": {
        "id": "egDs_caZTY8q"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[train.tag != 'Not-Tamil']"
      ],
      "metadata": {
        "id": "cdjAnJzmTyHI"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags = {\"tag\":     {'Hope-Speech':0, 'None-of-the-above':7, 'Homophobia':1, 'Misandry':2,\n",
        "       'Counter-speech':3, 'Misogyny':4, 'Xenophobia':5, 'Transphobic':6}}"
      ],
      "metadata": {
        "id": "6gxDAUsAUNnm"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.replace(tags)\n",
        "valid = valid.replace(tags)\n",
        "test = test.replace(tags)"
      ],
      "metadata": {
        "id": "RuE7vMtFUzkl"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.concat([train,valid],axis=0)"
      ],
      "metadata": {
        "id": "qXEcRozRVmT_"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY6Lh9snVtUk",
        "outputId": "281ae61f-12c6-4978-b16f-1933a0ea358c"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10227, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.drop(train[train['tag'] == 7].sample(frac=0.4).index)"
      ],
      "metadata": {
        "id": "kJrc_HuytwFe"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = pd.read_csv(\"/content/Tamil_test_labels_data.csv\")\n",
        "\n",
        "test_labels = test_labels.replace(tags)\n",
        "test_labels = pd.merge(test_labels, test, on=['comments'])\n",
        "test_labels = test_labels.dropna()"
      ],
      "metadata": {
        "id": "X8LFjK5iyUH1"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gt = []\n",
        "co = []\n",
        "for com in range(len(list(test_labels['comments']))):\n",
        "  if test_labels['comments'][com] in list(test['comments']):\n",
        "\n",
        "    gt.append(test_labels['tag'][com])\n",
        "    co.append(test_labels['comments'][com])"
      ],
      "metadata": {
        "id": "f9J99E3IyZf_"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(co)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "701vIHx4yjCF",
        "outputId": "6847dd2d-7ec5-46cb-9d70-4f3e6d303a9a"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2555"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def oversample(df):\n",
        "    classes = [4,0,1,6,5]\n",
        "    most = 250\n",
        "    classes_list = []\n",
        "    for key in classes:\n",
        "        classes_list.append(df[df['tag'] == key]) \n",
        "    classes_sample = []\n",
        "    for i in range(len(classes_list)):\n",
        "        classes_sample.append(classes_list[i].sample(most, replace=True))\n",
        "    df_maybe = pd.concat(classes_sample)\n",
        "    final_df = pd.concat([df_maybe,df], axis=0)\n",
        "    final_df = final_df.reset_index(drop=True)\n",
        "    return final_df"
      ],
      "metadata": {
        "id": "vEKU-mQct2Vy"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = oversample(train)"
      ],
      "metadata": {
        "id": "Jrl2mv3ot7YK"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenization of the train data"
      ],
      "metadata": {
        "id": "rSnr5z6MbH1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re, string\n",
        "from indicnlp.tokenize import indic_tokenize\n",
        "def tokenize(s): return indic_tokenize.trivial_tokenize(s)"
      ],
      "metadata": {
        "id": "ezKOgeFwU3gy"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = train.shape[0]\n",
        "\n",
        "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
        "                      strip_accents='unicode', use_idf=1,\n",
        "               smooth_idf=1, sublinear_tf=1)\n",
        "\n",
        "\n",
        "trn_term_doc = vec.fit_transform(train['comments'])\n",
        "test_term_doc = vec.transform(co)"
      ],
      "metadata": {
        "id": "7pysTr8JVHj8"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training the model on the training data"
      ],
      "metadata": {
        "id": "OqkZ_XE2a6he"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_cols = ['tag']"
      ],
      "metadata": {
        "id": "qzCweAheXmi6"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = trn_term_doc\n",
        "test_x = test_term_doc"
      ],
      "metadata": {
        "id": "GvxdUq6JVaLN"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pr(y_i, y):\n",
        "    p = x[y==y_i].sum(0)\n",
        "    return (p+1) / ((y==y_i).sum()+1)"
      ],
      "metadata": {
        "id": "oQEV7lVzVSzL"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.svm as svm\n",
        "import sklearn.ensemble\n",
        "\n",
        "def get_mdl(y):\n",
        "    y = y.values\n",
        "    r = np.log(pr(1,y) / pr(0,y))\n",
        "    m = sklearn.ensemble.GradientBoostingClassifier()\n",
        "    x_nb = x.multiply(r)\n",
        "    return m.fit(x_nb, y), r"
      ],
      "metadata": {
        "id": "R9d49XB_WiDm"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.zeros((len(test), len(label_cols)))\n",
        "\n",
        "for i, j in enumerate(label_cols):\n",
        "    print('fit', j)\n",
        "    m,r = get_mdl(train[j])\n",
        "    preds = m.predict(test_x.multiply(r))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONkHmHTuWk_f",
        "outputId": "56b7a460-2a4f-4b37-d3cb-13e618356799"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit tag\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Srov1HIuu5jp",
        "outputId": "0a7314be-501b-4189-e490-5f060f6e652f"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2555"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing the test data"
      ],
      "metadata": {
        "id": "fv9cbwAeanmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = pd.read_csv(\"/content/Tamil_test_labels_data.csv\")"
      ],
      "metadata": {
        "id": "Rwy8XaVPXpDn"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3r5dd-dbixZ",
        "outputId": "5969bf83-b320-44e8-9d45-4e5f4675ace0"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2559, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = test_labels.replace(tags)"
      ],
      "metadata": {
        "id": "5av1jK3GX04z"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = test_labels.dropna()"
      ],
      "metadata": {
        "id": "N4A_xXtRj4Qv"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgci5vyzbpyJ",
        "outputId": "c3b17074-8df1-41b6-d193-c59dfac68290"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2556, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the model using unseen test data"
      ],
      "metadata": {
        "id": "Zg8TuNq-atqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "\n",
        "print(sklearn.metrics.classification_report(gt, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFyPVQ5NYQDR",
        "outputId": "ab33c919-6409-44a8-dfa0-131360c1c0c9"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.13      0.19        95\n",
            "           1       0.62      0.39      0.48        64\n",
            "           2       0.71      0.47      0.56       419\n",
            "           3       0.63      0.18      0.28       135\n",
            "           4       0.44      0.23      0.30       105\n",
            "           5       0.65      0.33      0.44       120\n",
            "           6       0.37      0.25      0.30        60\n",
            "           7       0.72      0.93      0.81      1557\n",
            "\n",
            "    accuracy                           0.70      2555\n",
            "   macro avg       0.57      0.36      0.42      2555\n",
            "weighted avg       0.67      0.70      0.66      2555\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "E0ZBmymLYUfH"
      },
      "execution_count": 118,
      "outputs": []
    }
  ]
}